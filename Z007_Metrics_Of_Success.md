---
title: 11. Metrics Of Success
layout: default
nav_order: 13
---
# Metrics Of Success

### [Previous Chapter](Z006_Roadblocks_To_Teaching.html)

## **Short Answer**

Being the "best" is simply a title. Nothing more.

Two things make a "good" teacher:
1. Being better than other teachers
2. "When you do things right, people won't be sure you've done anything at all." (Futurama, 2002)

Metrics depend on goals and should be consistent and objective. Test scores are one type of metric to base performance on. Be wary of metrics enabling perverse incentives, or incentives encouraging undesireable, and/or unexpected, results (see cobra effect below). If a metric has no influence on answering someone's question or drive a real decision, it's probably a useless metric.

**Goodhart's Law (1975)** 
> When a measure becomes a target, it ceases to be a good measure.

**Campbell's Law (1979)**
> The more any quantitative social indicator is used for social decision-making, the more subject it will be to corruption pressures and the more apt it will be to distort and corrupt the social processes it is intended to monitor.

**The Cobra Effect:** A solution unintentionally makes a problem worse (Siebert, 2001).

When academics are a primary measure of a student's worth, a system may treat that student like a commodity. If grades are also a metric of success, a teacher/instructor, given their current position and power, can only reasonably grade work they receive. Interpret that as you will.

When money is tied to metrics of success, people do things they normally wouldn't do to positively affect, or even inflate, those metrics. 
- Just about everyone cares about money. 
- If they don't have enough money, they care about getting more money.
- If they have plenty of money, they care about keeping money (but also getting more).

**Metrics are like compasses/snapshots indicating failure/success in a system rather than evaluating and defining a distinct problem.** You use metrics to inform decisions a human should make, not to replace decisions humans make. A "good" metric is one that's meaningful, timely (or doesn't take long to measure), measureable, and understandable. If it lacks one of these aspects, it may not be a good metric to inform decisions.
- **Metrics are *diagnostic*, not prescriptive.**
- **Correlation does not imply causation.**

## **Long Answer**

There's a joke where, in education, we traded stamina for engagement.

Sadly, it isn't a joke. This chapter explains some parts on why a joke is now reality.

### **Why Metrics of Success?**

Even if you're not in business or finance, there are terms from those fields you should know. Metrics are measures to reveal whether your current system is performing as intended or requires changes. Measures are objective, and sometimes subjective, depending on user needs. These measures also apply to educational systems to determine the effectiveness of implementation based on its outcomes (U.S. Department of Education, 2025).

You want to choose the right metrics to gauge success. A single metric risks becoming a target to aim for. Using multiple metrics reduces that risk while simultaneously monitoring many areas. What those metrics are depends on the goals of the teacher and organization using them. Goals may include maximizing outcomes (scores, pass rates), cultivating qualitative aspects (engagement, relationships), or encouraging growth (attitudes, perspectives, character). It could also be a mix of these or just simply making it to the next day.

There are two types of data associated with metrics: quantitative and qualitative. Quantitative data is a specific and objective measure capturing numbers, quantities, and ranges. Qualitative data is based on subject and explanatory measures of qualities, traits, and characteristics. In short, quantitative is numbers and qualitative is words and images. Quantitative data may work alongside qualitative data, or separate from quantitative data, depending on your needs.

It is possible to convert qualitative data into quantitative data through methods like sentiment analysis, natural language processing (NLP), and machine learning (ML). You can convert from quantitative to qualitative, but it is rarely done outside of categorizing, bucketing, and labeling. Quantitative data also feeds models optimized through techniques like simulated annealing.

Details of these techniques are beyond this guide, but awareness helps if you decide to pursue deeper analysis later.

Measuring data may allow bias to creep in through various means like sampling choices and demographics . Interpretations and student factors may also introduce bias. Several examples of bias include, but are not limited to, the following (Rogers, Jonker, 2024):

- Confirmation bias
- Observer bias
- Selection bias
- Recall bias
- Reporting bias
- Sampling bias
- Survivorship bias
- Measurement bias
- Social bias

**Bias is unavoidable, unconscious or otherwise, and varies across person to person.** Unchecked and unaccounted bias will lead to detrimental effects. In the worst case, you may face legal and ethical consequences for inaccurate decisions made using the data collected and metrics produced. You can reduce bias with strict verifications, transparency, and representative sampling over selective subsets.

You may see two standard terms used for metrics of success: Objectives and Key Results (OKRs) and Key Performance Indicators (KPIs). OKRs track progress and direction toward specific goals and KPIs monitor performance and outcomes over time. KPIs are better for recurring tasks while OKRs are better for one-off tasks. OKRs often use qualitative data while KPIs use quantitative data.

Any metric can be "gamed" or optimized. Despite this, the teacher/instructor goal of ensuring students learn what you teach remains. 

### **Metrics (In General)**

One area of quantitative data comes from metrics for student success. Some quantitative examples include (Fields, 2024):

- GPA/Grades (Academic Performance)
- Support Service Utilization (Accommodations)
- Time to Completion
- Graduation Rate
- Retention Rate
- Post-Graduate Employment Rate
- Test Scores (State, ACT, SAT, IB, AP, etc.)
- Attendance & Participation

Generally speaking, a student metric deals with performance, growth, and development. You may also track metrics like GPA and test scores through other, related metrics such as proficiency rates. This is when students are bucketed based on performance and you want to showcase a high  percentage scoring at or above, for example, a "proficient" level.

Most analysis of results should be treated as a snapshot rather than a valid performance evaluation. This may be because only a single metric is focused at a time, there are insufficient growth models, or multiple metrics aren't used in conjunction for analysis. For example, if using gap analysis, or even analysis in general, to analyze education results, it may have critical flaws for three reasons:
1. Typical experiments test the same group, or same subject, before and after an experiment to isolate effects and ensure only one variable is changed at a time. School environments rarely, if ever, allow for this controlled testing.
2. A given grade level educates different groups of students each new academic period.
3. A bad score given one year may improve the next year, despite no changes implemented by a school/teacher, due to the *students* changing.

There's also metrics not related just to students, but also staff members (and sometimes parents). These may focus on morale, finances, and general resource allocation. Some examples include:
- Parent Engagement
- Teacher Retention
- Morale and Satisfation
- School Quality (physical conditions primarily)
- Per-Pupil Expenditure
- Teacher Qualifications
- Teacher-to-Student Ratio
- Counselor-to-Student Ratio

There are a whole host of metrics, but there's a few I want to call out because I usually see them as "objectives" rather than performance indicators.

### **Diagnostics with Metrics**

Let's say you're tracking a particular metric, or a group of metrics, and you notice values that don't look good.

Before you jump to conclusions and implement new changes, realize one fact: quantitative data (and qualitative to some degree) is good at revealing *what* is happening, but not *why* something is happening, how something is happening, or if the metric is even valid to continue measuring in the first place.
- It's possible to mitigate the *why* issue through additional metrics, but it may not fully solve the problem of why.

To dive into one metric example: tracking attendance.

Attendance is low this year. It could be from one student chronically absent, absences from multiple students, or another factor or a combination of factors. 
- From this information alone so far, you can reasonably assume students are not going to school. 
- This is your *what;* the problem.
- You don't have a *why* yet.

Do not draw any conclusions from the above; you're only identifying problems so far.

As for why it's happening, you'll need to investigate, collect evidence, and look into other underlying issues. These issues may conflict with each other, seem unrelated to a problem, or not be identified with data alone. Some examples of investigation points may include:
- Are there bullying problems or social conflicts?
- Is there an issue outside of school, at home, or in the environment?
- Were new, external policies implemented affecting attendance?
- Does the student not perceive value in the class or material?
- Are there resources lacking to help with attendance?
- What other metrics might indicate an issue alongside low attendance?
- Is there an issue with the management of a class?
- Do underlying needs indicate a symptom of another problem (e.g. bad behavior as a symptom of boredom)?
- Are there other logistical barriers present with parents, staff, and other peers?
- Is there a change in demographics?

Once you start identifying which issues exist, and if they're *valid* issues that exist, then you can gather data for them, then disaggregate the data to determine how universal or specific a problem is.

After data is collected and process, then you can effective design whatever solution is needed to solve the problem(s). Keep in mind three things, however:
- A seemingly good solution may actually generate more problems than before. 
- Even the perfect solution can still fail due to factors outside of your control.
- Designing solutions for problems and issues which don't exist is a waste of time, a waste of resources, and a detriment to every involved.

### **The White and Orange Exception**

There's an example I like to talk about where a better result occurs in practice despite established metrics saying it's worse: white text on orange background in a button. 
- There's even [a dedicated case study on this topic](https://www.bounteous.com/insights/2019/03/22/orange-you-accessible-mini-case-study-color-ratio/) from Ericka O'Connor (2019).

Designs need to consider similar accessibility laws. Instead of ESSA and LRE, however, it's ADA, Section 508, and WCAG (Web Content Accessibility Guidelines). Someone may still risk legal actions if they aren't designing with consideration for these rules.

There were two main levels of WCAG compliance, AA and AAA, when the case study was written in 2019. Designs should meet a minimum contrast ratio of at least AA, or 4.5 for small text and 3 for large text, but a higher "value" is generally better. For reference, contrast ratio is how well text of one color appears against a background of another color.

In that same article, the contrast ratio for black text on orange background was 6.44, or AA, while the contrast ratio for white text on orange background was 3.26, or AA (for large text requirements). Despite metrics indicating black was better, white text had a human factor play where 61% of participants found white on orange was easier to read compared to 39% with black on orange.

This exception is here to remind you of two things:
1. Metrics are not always perfect and still diagnostic.
2. You should still aim to meet some level of standard(s) even if all metrics aren't perfectly favorable.

### **100% Graduation Rate**

This is a funny metric to use for success and the same applies for job placement rate. It's also a case of why you need *multiple* metrics of success instead of just one to help verify data authenticity, and why making a metric a target proves Goodhart's Law.

100% graduation rate means you're telling me *every* student in the school (or specific year) got passing grades on every subject they went through?

If you see this value, be skeptical. Be doubly skeptical if it comes from a school with a large pipeline of students (i.e. a large sample/population size) going through it.
- I'd also be skeptical of >=95% as well, but that's my personal opinion.
- You'd also want to reference standardized scores the school achieves for testing it cannot easily manipulate, like SAT and ACT scores.

There's two immediate ways that came to my mind to manipulate this.
1. Lower the standards for what is considered "graduation"
2. Pad grades and/or implement a minimum grade policy across the board

*Which of these can you implement right now at zero to low cost?*

If you guessed #1 *and* #2, you are correct. It is disturbly easy to accomplish these methods as well, even if they're legally and ethically questionable. 

A school system, across its entire journey, should function as a increasingly more difficult filter and impose more responsibilities and accountability as students age. When this metric, and related success metrics, are manipulated to display good results, it undermines the entire intellectual journey and affects the education system *as a whole* at the expense of every student. If you manipulate what counts as success and lower the standards to meet success, or also remove accountability for students not meeting educational expectations, it removes legitimate standards to prepare students for what comes next in their lives.

### **Average Daily Attendance (ADA)**

Generally speaking, you *want* students to attend class. Despite good intentions, this metric directly links attendance numbers to financial resources like increased budgets. It's also a metric mostly outside of your control thanks to a few factors:
- The parents (or students themselves if adults) are responsible for ensuring a student gets to school.
- Students could still get to school, but not attend classes of their own volition.
- There's a strong association between socioeconomic status of students (and their parents) and school attendance (Klein et al., 2020).
    - i.e. Lower resources = more absences

Everyone cares about money. If they have enough money, then they care about not losing money. A school (and by extension a business) is no different as they want funding to continue operations. If a school cannot perform well, they may receive reduced funding from various sources (federal, state, and local). This reduced funding may occur even when it is objectively impossible to meet attendance goals set by entities outside facilities as well. A slash in funding may also lead to a downward spiral in performance as well, which is difficult to recover from.

If this is a success metric, it has real world value often tied to wealth, budgets, and income, so policies may change to try and improve it because money is important. Some policy change examples, which may be good or bad depending on your perspective, include:
- Heavily enforcing truancy laws
- Redefining policies to keep students *in* classrooms
    - This may mean not enforcing consequences which take students out of classrooms as it may affect attendance metrics
- Raising awareness of the effects of excessive absences
- Investing in resources, like improvement plans, to mitigate absences
- Linking number of absences to reduced benefits and privileges available to students
- Potentially faking attendance records
- Altering what counts as excused vs unexcused absences, and what is an "absence" in general

On the other side of the coin, you may focus on chronic absentee rate (or, from a business perspective, "churn rate"). This typically means students with 10% or more school days missed for any reason in a given period of time. That metric may employ similar strategies and tactics like the examples above to make it look good to "investors" and other onlookers.

### **Enrollment Metrics**

Enrollment is another metric I've seen used to boast how effective a class, school, or otherwise is. However, it suffers a potential problem as a vanity metric vs a meaningful metric and this problem is more pronounced when it's measured in isolation.

For anyone familiar with MMORPGS, video games, or other forms of media, you may have seen terms like the following before similar to enrollment as a metric:
- Subscriber Counts
- Total Number of Players/Subscribers
- Concurrent Players (or "Current")
- Most Played Game

If this is a success metric, you may perform mass adoption strategies, or reaching the maximum audience available to you, to showcase improvement and success. Enrollment, as a metric, generally only cares about number of students *in* a given class/school. It does not care about the performance of those students or what those students do while inside of the school.
- Video game example: A game can sell 5 million copies, but if 4 million players quit before completing the game, it's not an accurate indication of success.

Though generally you want high enrollment, you may risk pursuing high enrollment at the cost of other metrics such as:
- Engagement
- Perfomance
- Retention

It's not to say enrollment is entirely a bad metric. For example, let's say you track enrollment numbers and there's a sudden drop in students from one year to the next year. This is indicative of a problem warranting investigation and figuring out what the cause is.

### **Test Scores**

This is typically used to indicate student understanding of material across various grade levels. It's often examined alongside other metrics, such as attendance and GPA, and is a metric sometimes outside of the control of a teacher or school.

It's also possible to "game" this metric by managing the test-taking population itself, such as:
- Over-identification of accommodations for students on tests, such as extended time.
- Getting low-scoring students to not appear on test days

State tests and standardized tests are usually the subjects of these metrics. If, however, these metrics are defined as success criteria, especially with money attached, some things may happen at a school:
- The curriculum shifts to focus on tested subjects.
- Subjects not covered on these tests may be neglected.
- Skills not tested or harder to assess on tests may be sidelined in favor of easily defineable skills.
- The classroom goes from a place of genuine learning and discovery to a place specifically designed to get high test scores.
- Accountability may be sacrificed if it means increasing the metric.

To maximize this metric, you may risk the well-being of both high-performing and low-performing students, which means a failure in equitable education for all students.

You may also see more instances of cheating, higher pressures on students to do well, and educators altering test scores to showcase higher results than actually earned. Many of these actions have real incentives promoting more desperate behaviors, such as college admissions, scholarships, company and job placements, and more based on test scores and performance.

### **No Child Left Behind and Every Student Succeeds Act**

Normally I'd place these in the Legality chapter, but I believe these acts apply better to this chapter. It'll also be tough to talk about this without bias, so I apologize in advance and will try my best.

For context, No Child Left Behind doesn't exist anymore. It was sunsetted and replaced in 2015 with the Every Student Succeeds Act (Hirschfeld Davis, 2015).

If you were to ask many experienced teachers who worked during the late 1990's and early 2000's about these acts, they might call it "the politicization of education" as it changes the focus to standardized testing and meeting metrics; typically at the cost of everything else.
- It's cutting instruction time to prove instruction is effective (i.e. a focus on testing at the exclusion of other items).
- It also encouraged passing up students into higher grades, despite clear evidence they are not ready to progress in the next step of their learning journey (i.e. grade inflation to prevent failure).

To avoid delving into politics too much, the most practical consequence of not meeting outlined goals and requirements was a loss of funding. Though there was "no child left behind" and "every student succeeds" ***on paper***, students were left behind in practice.
- E.g. A 12th grader with a 5th grade reading level eligible for graduation.

These acts are responsible for establishing metrics as a target to meet, which means the education system changes, for better or for worse, towards a metrics-based system. You may also see more staff and more bureaucracy, at the administrative or support level, to hold people responsible for meeting these metrics. You may also see an increase in perverse incentives or initiatives which, despite good intentions, usually backfire.

### **What about if the entire class fails?**

Well, that depends. Which one of the two probable scenarios is it below?
- If it isn't one of these (which is possible!), then select the one it may be closer to.

**A: Did the entire class do the assignments, exercises, exams, etc. and still fail?**

**B: Did the entire class *not* do assigned work, which is left ungraded and brings down their overall grade to failing?**

If it's scenario A, and includes the students that genuinely did try their best and still fail, it's likely the teacher's fault. If it's scenario B, it's more likely the student's fault.
- Notice how I'm saying *likely* and not answering with certainty. Metrics are diagnostic and there could be another underlying problem present.

Overall, it's an application of the classic saying: bring a horse to water, but can't make it drink. If you're a teacher or instructor reading this, document their failures and be prepared to present a case about it if it happens. About all I can reliably say here.

## **Bibliography**

1. Campbell, Donald T (1979). *Assessing the impact of planned social change.* Evaluation and Program Planning. 2 (1): 67–90. [doi:10.1016/0149-7189(79)90048-X](https://doi.org/10.1016%2F0149-7189%2879%2990048-X).

1. Fields, E. (2024, November 15). *How do you measure student success?* Enrollify. [https://www.enrollify.org/blog/how-do-you-measure-student-success](https://www.enrollify.org/blog/how-do-you-measure-student-success)

2. “Futurama” Godfellas (TV Episode 2002) - Quotes - IMDb. (2025). IMDb. [https://www.imdb.com/title/tt0756880/quotes/](https://www.imdb.com/title/tt0756880/quotes/)

3. Goodhart, C. (1975). *Problems of Monetary Management: The UK Experience.* Papers in Monetary Economics. Papers in monetary economics 1975; 1; 1. - [Sydney]. - 1975, p. 1-20. Vol. 1. Sydney: Reserve Bank of Australia.

1. Hirschfeld Davis, J. (2015, December 11). President Obama Signs Into Law a Rewrite of No Child Left Behind. The New York Times. [https://www.nytimes.com/2015/12/11/us/politics/president-obama-signs-into-law-a-rewrite-of-no-child-left-behind.html](https://www.nytimes.com/2015/12/11/us/politics/president-obama-signs-into-law-a-rewrite-of-no-child-left-behind.html)

1. Klein, M., Sosu, E. M., & Dare, S. (2020). Mapping inequalities in school attendance: The relationship between dimensions of socioeconomic status and forms of school absence. Children and Youth Services Review, 118(118), 105432. [https://doi.org/10.1016/j.childyouth.2020.105432](https://doi.org/10.1016/j.childyouth.2020.105432)
    - Alt Link: [https://www.sciencedirect.com/science/article/pii/S0190740920303698](https://www.sciencedirect.com/science/article/pii/S0190740920303698)

1. O'Connor, Ericka. (2019, March 22). *Orange You Accessible? A Mini Case Study on Color Ratio | Bounteous.* www.bounteous.com. [https://www.bounteous.com/insights/2019/03/22/orange-you-accessible-mini-case-study-color-ratio/](https://www.bounteous.com/insights/2019/03/22/orange-you-accessible-mini-case-study-color-ratio/)

2. Rogers, J., & Jonker, A. (2024, October 4). *What is data bias?* IBM. [https://www.ibm.com/think/topics/data-bias](https://www.ibm.com/think/topics/data-bias)

1. Siebert, Horst (2001). *Der Kobra-Effekt. Wie man Irrwege der Wirtschaftspolitik vermeidet* (in German). Munich: Deutsche Verlags-Anstalt. [ISBN 3-421-05562-9](https://isbnsearch.org/isbn/3421055629).

4. U.S. Department of Education, Office of Career, Technical, and Adult Education. (2025, January 15). *Performance measures and accountability*. [https://www.ed.gov/about/ed-offices/octae/performance-measures-and-accountability](https://www.ed.gov/about/ed-offices/octae/performance-measures-and-accountability)

## **[Next Chapter](Z007x_Math_And_Calculus.html)**